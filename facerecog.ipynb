{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0111a191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac35e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp/ipykernel_30960/3632878736.py:7: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  if faces == ():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting samples is completed !!!\n"
     ]
    }
   ],
   "source": [
    "def generate_dataset():\n",
    "    face_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "    def face_cropped(img):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "        if faces == ():\n",
    "            return None   \n",
    "        for (x,y,w,h) in faces:\n",
    "            cropped_face = img[y:y+h,x:x+w]\n",
    "        return cropped_face\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    img_id = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if face_cropped(frame) is not None:\n",
    "            img_id+=1\n",
    "            face = cv2.resize(face_cropped(frame), (200,200))\n",
    "            face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "            file_name_path = \"C:/Users/Asus/Desktop/dedrite/data/\"+\"harsh.\"+str(img_id)+\".jpg\"\n",
    "            #file_name_path = \"C:/Users/Asus/Desktop/dedrite/data/Images for visualization/\"+str(img_id)+'.jpg'\n",
    "            cv2.imwrite(file_name_path, face)\n",
    "            cv2.putText(face, str(img_id), (50,50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2 )\n",
    "            \n",
    "            cv2.imshow(\"Cropped_Face\", face)\n",
    "            if cv2.waitKey(1)==13 or int(img_id)==40:\n",
    "                break\n",
    "                 \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Collecting samples is completed !!!\")\n",
    "generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a875eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_label(image_name):\n",
    "    name = image_name.split('.')[-3]\n",
    "    if name==\"harsh\":\n",
    "        return np.array([1,0,0])\n",
    "    elif name==\"ayush\":\n",
    "        return np.array([0,1,0])\n",
    "    elif name==\"disha\":\n",
    "        return np.array([0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fc657ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6474373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_data():\n",
    "    data = []\n",
    "    for img in tqdm(os.listdir(\"data\")):\n",
    "        path=os.path.join(\"data\",img)\n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        data.append([np.array(img_data), my_label(img)])\n",
    "    shuffle(data) \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "262ef20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 358.80it/s]\n"
     ]
    }
   ],
   "source": [
    "data = my_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfb3335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 50, 50, 1)\n",
      "(30, 50, 50, 1)\n"
     ]
    }
   ],
   "source": [
    "train = data[:70]  \n",
    "test = data[70:]\n",
    "X_train = np.array([i[0] for i in train]).reshape(-1,50,50,1)\n",
    "print(X_train.shape)\n",
    "y_train = [i[1] for i in train]\n",
    "X_test = np.array([i[0] for i in test]).reshape(-1,50,50,1)\n",
    "print(X_test.shape)\n",
    "y_test = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26376bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[228]\n",
      "   [230]\n",
      "   [231]\n",
      "   ...\n",
      "   [226]\n",
      "   [225]\n",
      "   [225]]\n",
      "\n",
      "  [[229]\n",
      "   [229]\n",
      "   [229]\n",
      "   ...\n",
      "   [226]\n",
      "   [225]\n",
      "   [225]]\n",
      "\n",
      "  [[228]\n",
      "   [229]\n",
      "   [229]\n",
      "   ...\n",
      "   [225]\n",
      "   [224]\n",
      "   [225]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73]\n",
      "   [ 68]\n",
      "   [ 75]\n",
      "   ...\n",
      "   [ 57]\n",
      "   [ 57]\n",
      "   [ 59]]\n",
      "\n",
      "  [[ 72]\n",
      "   [ 73]\n",
      "   [ 74]\n",
      "   ...\n",
      "   [ 56]\n",
      "   [ 55]\n",
      "   [ 55]]\n",
      "\n",
      "  [[ 66]\n",
      "   [ 72]\n",
      "   [ 73]\n",
      "   ...\n",
      "   [ 52]\n",
      "   [ 57]\n",
      "   [ 55]]]\n",
      "\n",
      "\n",
      " [[[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]]\n",
      "\n",
      "\n",
      " [[[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[232]\n",
      "   [227]\n",
      "   [225]\n",
      "   ...\n",
      "   [107]\n",
      "   [118]\n",
      "   [129]]\n",
      "\n",
      "  [[235]\n",
      "   [230]\n",
      "   [254]\n",
      "   ...\n",
      "   [115]\n",
      "   [130]\n",
      "   [127]]\n",
      "\n",
      "  [[241]\n",
      "   [238]\n",
      "   [221]\n",
      "   ...\n",
      "   [122]\n",
      "   [127]\n",
      "   [129]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 97]\n",
      "   [ 99]\n",
      "   [100]\n",
      "   ...\n",
      "   [ 75]\n",
      "   [ 70]\n",
      "   [ 74]]\n",
      "\n",
      "  [[ 83]\n",
      "   [ 88]\n",
      "   [ 87]\n",
      "   ...\n",
      "   [ 68]\n",
      "   [ 63]\n",
      "   [ 64]]\n",
      "\n",
      "  [[ 79]\n",
      "   [ 80]\n",
      "   [ 77]\n",
      "   ...\n",
      "   [ 63]\n",
      "   [ 59]\n",
      "   [ 60]]]\n",
      "\n",
      "\n",
      " [[[228]\n",
      "   [230]\n",
      "   [231]\n",
      "   ...\n",
      "   [225]\n",
      "   [225]\n",
      "   [224]]\n",
      "\n",
      "  [[228]\n",
      "   [229]\n",
      "   [230]\n",
      "   ...\n",
      "   [226]\n",
      "   [225]\n",
      "   [225]]\n",
      "\n",
      "  [[228]\n",
      "   [230]\n",
      "   [230]\n",
      "   ...\n",
      "   [225]\n",
      "   [225]\n",
      "   [223]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 76]\n",
      "   [ 72]\n",
      "   [ 74]\n",
      "   ...\n",
      "   [ 56]\n",
      "   [ 56]\n",
      "   [ 59]]\n",
      "\n",
      "  [[ 69]\n",
      "   [ 72]\n",
      "   [ 73]\n",
      "   ...\n",
      "   [ 59]\n",
      "   [ 54]\n",
      "   [ 53]]\n",
      "\n",
      "  [[ 66]\n",
      "   [ 75]\n",
      "   [ 69]\n",
      "   ...\n",
      "   [ 53]\n",
      "   [ 60]\n",
      "   [ 57]]]\n",
      "\n",
      "\n",
      " [[[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]\n",
      "\n",
      "  [[  0]\n",
      "   [  0]\n",
      "   [  0]\n",
      "   ...\n",
      "   [  0]\n",
      "   [  0]\n",
      "   [  0]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b02fdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5647ef5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\asus\\anaconda3\\lib\\site-packages (2.11.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (22.11.23)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.47.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.19.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.20.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.2)\n",
      "\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a8e45d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Asus\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56c6fde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.09525\u001b[0m\u001b[0m | time: 0.048s\n",
      "| Adam | epoch: 012 | loss: 1.09525 - acc: 0.3540 -- iter: 64/70\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.11476\u001b[0m\u001b[0m | time: 1.100s\n",
      "| Adam | epoch: 012 | loss: 1.11476 - acc: 0.3013 | val_loss: 0.93364 - val_acc: 0.6333 -- iter: 70/70\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#tf.reset_default_graph()\n",
    "tf.compat.v1.reset_default_graph()\n",
    "convnet = input_data(shape=[50,50,1])\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "# 32 filters and stride=5 so that the filter will move 5 pixel or unit at a time\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "convnet = fully_connected(convnet, 3, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate = 0.001, loss='categorical_crossentropy')\n",
    "model = tflearn.DNN(convnet, tensorboard_verbose=1)\n",
    "model.fit(X_train, y_train, n_epoch=12, validation_set=(X_test, y_test), show_metric = True, run_id=\"FRS\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7146813e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_for_visualization():\n",
    "    Vdata = []\n",
    "    for img in tqdm(os.listdir(\"Images for visualization\")):\n",
    "        path = os.path.join(\"Images for visualization\", img)\n",
    "        img_num = img.split('.')[0] \n",
    "        img_data = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        img_data = cv2.resize(img_data, (50,50))\n",
    "        Vdata.append([np.array(img_data), img_num])\n",
    "    shuffle(Vdata)\n",
    "    return Vdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5f1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vdata = data_for_visualization()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt   # pip install matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for num, data in enumerate(Vdata[:20]):\n",
    "    img_data = data[0]\n",
    "    y = fig.add_subplot(5,5, num+1)\n",
    "    image = img_data\n",
    "    data = img_data.reshape(50,50,1)\n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1:\n",
    "        my_label = 'ayush'\n",
    "    elif np.argmax(model_out) == 0:\n",
    "        my_label = 'harsh'\n",
    "    else:\n",
    "        my_label = 'disha'\n",
    "        \n",
    "    y.imshow(image, cmap='gray')\n",
    "    plt.title(my_label)\n",
    "    \n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a9bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import the crucial library\n",
    "from keras import applications\n",
    "# importing the model\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "# importing the call backs \n",
    "from keras import callbacks\n",
    "# importing required layers\n",
    "from keras.models import Sequential\n",
    "# importing crucial layers\n",
    "from keras.layers import Flatten,BatchNormalization,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2822ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71686520/71686520 [==============================] - 13s 0us/step\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb4 (Functional)  (None, 1792)             17673823  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 8965      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,682,788\n",
      "Trainable params: 17,557,581\n",
      "Non-trainable params: 125,207\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.pooling import GlobalAveragePooling2D  \n",
    "# importing layers \n",
    "from keras.layers import Dense\n",
    "# to import the dense layer\n",
    "\n",
    "efficient_net = EfficientNetB4(   # initializing the model efficientnet\n",
    "    weights='imagenet',\n",
    "    input_shape=(255,255,3), # defining the shape \n",
    "    include_top=False,\n",
    "    pooling='max'\n",
    ")\n",
    "\n",
    "Efficient_Model = Sequential()\n",
    "# defining the input layer\n",
    "Efficient_Model.add(efficient_net)\n",
    "# adding the dense layer\n",
    "Efficient_Model.add(Dense(units = 5, activation='softmax'))\n",
    "# last result layer of the algorithm efficient net\n",
    "Efficient_Model.summary()\n",
    "# to print the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e76d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the optimizer and compiling the code\n",
    "Efficient_Model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['Accuracy'])  # to compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9c21e0c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29124/2891908126.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = Efficient_Model.fit(  #  to trained the model \n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# initializing the epochs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# initializing the bs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     validation_data = (X_test, y_test))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\version_utils.py\u001b[0m in \u001b[0;36mdisallow_legacy_graph\u001b[1;34m(cls_name, method_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;34m\"eager mode enabled.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         )\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Calling `Model.fit` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.fit` with eager mode enabled."
     ]
    }
   ],
   "source": [
    "history = Efficient_Model.fit(  #  to trained the model \n",
    "    X_train, y_train,\n",
    "    epochs =100,  # initializing the epochs \n",
    "        batch_size = 28,  # initializing the bs\n",
    "    validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6836aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 12s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_max_pooling2d (Globa  (None, 512)              0         \n",
      " lMaxPooling2D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,979,909\n",
      "Trainable params: 265,221\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Flower_X_TRAIN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29124/2216407968.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m#to trained the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m history = vgg16_model1.fit(Flower_X_TRAIN,Flower_Y_TRAIN,\n\u001b[0m\u001b[0;32m     49\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# defining the iterations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m           \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFlower_X_VAL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFlower_Y_VAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Flower_X_TRAIN' is not defined"
     ]
    }
   ],
   "source": [
    "# *VGG-16*\n",
    "\n",
    "import keras,os\n",
    "# importing library\n",
    "from keras.models import Sequential\n",
    "# importing basic required layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation,GlobalMaxPooling2D\n",
    "# importing the model\n",
    "from keras.models import Model\n",
    "# importing the basic \n",
    "from keras import optimizers , layers, applications\n",
    "#importing vgg16 model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "#initializing the algorithm\n",
    "vgg16 = VGG16(input_shape = (224,224,3),weights = \"imagenet\", include_top = False)\n",
    "\n",
    "for layer in vgg16.layers:\n",
    "  # making the trainable layer in vgg 19 as false.\n",
    "    layer.trainable = False \n",
    "\n",
    "# defining the last layer\n",
    "last_layer = vgg16.get_layer('block5_pool')\n",
    "# to add the result layer\n",
    "last_output = last_layer.output\n",
    "# adding a layer to combined into fixed shape\n",
    "x = GlobalMaxPooling2D()(last_output)\n",
    "# Adding a hidden layer\n",
    "x = Dense(512, activation='relu')(x)\n",
    "# Adding a layer of dropout\n",
    "x = Dropout(0.5)(x)\n",
    "# adding an output layer\n",
    "x = Dense(5, activation='softmax')(x)\n",
    "\n",
    "vgg16_model1 = Model(vgg16.input, x) \n",
    "# initializing the model\n",
    "\n",
    " # to debug the algorithm\n",
    "vgg16_model1.compile(loss='categorical_crossentropy',   \n",
    "                # debugging the algorithm\n",
    "             optimizer='Adam',\n",
    "             # initializing the optimizer\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "vgg16_model1.summary() # function to show the summary\n",
    "\n",
    "#to trained the algorithm\n",
    "history = vgg16_model1.fit(Flower_X_TRAIN,Flower_Y_TRAIN,\n",
    "          epochs = 20, # defining the iterations \n",
    "          validation_data = (Flower_X_VAL,Flower_Y_VAL),\n",
    "          batch_size = 32 )\n",
    "\n",
    "# to import the c_r\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "# importing basic library of c_m\n",
    "pred1 = vgg16_model1.predict(Flower_X_TEST)\n",
    "# initializing predict variable\n",
    "pred1_T = vgg16_model1.predict(Flower_X_TRAIN)\n",
    "\n",
    "\n",
    "print(classification_report(np.argmax(Flower_Y_TEST, axis=1), np.argmax(pred1, axis=1))) \n",
    "print() # for testing score\n",
    "print('Testing Accuracy : ', accuracy_score(np.argmax(Flower_Y_TEST, axis=1), np.argmax(pred1, axis=1)))\n",
    "print() # for training score\n",
    "print('Training Accuracy : ', accuracy_score(np.argmax(Flower_Y_TRAIN, axis=1), np.argmax(pred1_T, axis=1)))\n",
    "\n",
    "# importing some important functions\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "print('Precision by RF of testing data is: %.3f' % precision_score(np.argmax(Flower_Y_TEST, axis=1), np.argmax(pred1, axis=1),average='micro')) \n",
    "# checking the precision value\n",
    "print('Recall by RF of testing data is: %.3f' % recall_score(np.argmax(Flower_Y_TEST, axis=1), np.argmax(pred1, axis=1),average='micro')) \n",
    "# checking the recall value\n",
    "print('F1 score by RF of testing data is: %.3f' % f1_score(np.argmax(Flower_Y_TEST, axis=1), np.argmax(pred1, axis=1),average='micro')) \n",
    "# checking the f2 score\n",
    "\n",
    "# importing cm\n",
    "from sklearn.metrics import confusion_matrix \n",
    "# initializing the c_m\n",
    "cm = confusion_matrix(np.argmax(y_test, axis=1), np.argmax(pred1, axis=1))\n",
    "\n",
    "# plotting cm\n",
    "import seaborn as sns\n",
    "# assigning the shape \n",
    "plt.figure(figsize=(10,10))\n",
    "# assigning heat map color\n",
    "sns.heatmap(cm,annot=True,cmap=random.choice(cmap),  fmt='d')\n",
    "# defining its x-axis name \n",
    "plt.xlabel('Predicted values')\n",
    "# dfining its y-axis name\n",
    "plt.ylabel('Original Values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86e0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
